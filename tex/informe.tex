\documentclass[a4paper,10pt,twoside]{article}

\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}
\usepackage[utf8]{inputenc}
\usepackage[spanish,es-ucroman,es-noquoting]{babel}
\usepackage{setspace}
\usepackage{fancyhdr}
\usepackage{lastpage}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{verbatim}
\usepackage{float}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{algorithmic}
\usepackage{amssymb}
\usepackage{url}
\usepackage{moreverb}


% Evita que el documento se estire verticalmente para ocupar
% el espacio vacío en cada página.
\raggedbottom


%%%%%%%%%% Configuración de Fancyhdr - Inicio %%%%%%%%%%
\pagestyle{fancy}
\thispagestyle{fancy}
\lhead{Trabajo Práctico 2, Organización del Computador II}
\rhead{Capra, Lovisolo, Petaccio}
\renewcommand{\footrulewidth}{0.4pt}
\cfoot{\thepage /\pageref{LastPage}}

\fancypagestyle{caratula} {
   \fancyhf{}
   \cfoot{\thepage /\pageref{LastPage}}
   \renewcommand{\headrulewidth}{0pt}
   \renewcommand{\footrulewidth}{0pt}
}
%%%%%%%%%% Configuración de Fancyhdr - Fin %%%%%%%%%%

\newcommand{\real}{\mathbb{R}}

\begin{document}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Carátula                                                                  %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\thispagestyle{caratula}

\begin{center}

\includegraphics[height=2cm]{DC.png} 
\hfill
\includegraphics[height=2cm]{UBA.jpg} 

\vspace{2cm}

Departamento de Computación,\\
Facultad de Ciencias Exactas y Naturales,\\
Universidad de Buenos Aires

\vspace{2cm}

\begin{spacing}{1}
\begin{Huge}

Reconocimiento de Dígitos Manuscritos\\
con la Descomposición en Valores Singulares

\end{Huge}
\end{spacing}

\vspace{2cm}

Trabajo Práctico 1, \\
Métodos Numéricos, \\
Primer Cuatrimestre de 2013

\vspace{3cm}

\begin{tabular}{|c|c|c|}
\hline
Apellido y Nombre & LU & E-mail\\
\hline
María Candela Capra Coarasa & 234/11 & canduh\_27@hotmail.com\\
Leandro Lovisolo            & 645/11 & leandro@leandro.me\\
Lautaro José Petaccio       & 443/11 & lausuper@gmail.com\\
\hline
\end{tabular}

\end{center}

\vspace{3cm}

\textbf{Resumen:} \\
Se implementa un método de reconocimiento de dígitos manuscritos basado en la descomposición en valores singulares, y se analizan empíricamente los parámetros principales del método.

\textbf{Palabras clave:}
OCR, dígitos manuscritos, reconocimiento, SVD, algoritmo QR.

\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Índice                                                                    %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\tableofcontents

\newpage


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Introducción Teórica                                                      %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Introducción Teórica}

\subsection{Conceptos}

\subsubsection{Media}
La media ($\bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i$) es un promedio estándard comunmente relacionado con la distribución probabilística Normal. El promedio es la esperanza de esta distribución.

En nuestro caso se utilizará la media de las columnas de la matriz que utilizaremos para el método OCR.

\subsubsection{Varianza}
La varianza es una medida de dispersión definida como la esperanza del cuadrado de la desviación de dicha variable respecto a su media.

En nuestro caso, debido a que utilizaremos una matríz para el método de OCR, el cálculo de la varianza será: $\sigma x_i = \frac{1}{n-1} \sum_{j=1}^{n} (x_i^{(j)} - \bar{x}_i)^2$.

\subsubsection{Matriz de covarianza}
La covarianza es un valor que indica el grado de variación conjunta de dos variables aleatorias, su ecuación es la siguiente:

 $\sigma x_k,x_j = \frac{1}{n-1} \sum{i=1}^{n} (x_k^{(i)} - \bar{x}_k)(x_j^{(i)} - \bar{x}_j) = \frac{1}{n-1}(x_k - \bar{x}_k)^{t}(x_j - \bar{x}_j)$

Dadas las imágenes utilizadas para el caso en formas de fila en la matriz (la llamaremos matriz A), la matriz de covarianza se construye de la siguiente forma:

$Mx = \frac{1}{n-1} X^{t}X = 
 \begin{pmatrix}
  \sigma x_1,x_1 & \sigma x_1,x_2 & \cdots & \sigma x_1,x_n \\
  \sigma x_2,x_1 & \sigma x_2,x_2 & \cdots & \sigma x_2,x_n \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  \sigma x_n,x_1 & \sigma x_n,x_2 & \cdots & \sigma x_n,x_n \\
 \end{pmatrix}
$
\\
Siendo la matriz $X = 
 \begin{pmatrix}
  a_{1,1} - \bar{a_1} & a_{1,2} - \bar{a_2} & \cdots & a_{1,m} - \bar{a_m} \\
  a_{2,1} - \bar{a_1} & a_{2,2} - \bar{a_2} & \cdots & a_{2,m} - \bar{a_m} \\
  \vdots  & \vdots  & \ddots & \vdots  \\
  a_{n,1} - \bar{a_1} & a_{n,2} - \bar{a_2} & \cdots & a_{n,m} - \bar{a_m} \\
 \end{pmatrix}
$

Se utiliza la matríz de covarianza para poder realizar luego una reducción de la redundancia en la información (reduciendo la covarianza) obteniendo los datos impresindibles y necesarios para la aplicación del método elegido de OCR.

La matriz de covarianza cuenta con la propiedad de ser simétrica, dado que $X^{t}X = (X^{t}X)^{t} = (X^{t}X^{t^{t}}) = X^{t}X$ permitiendo la utilización de métodos como QR para conseguir sus autovectores y autovalores.

\subsubsection{Diagonalización de la matriz}
\textbf{Teorema:}
Si $\mathnormal{B} \in \mathbb{R}^{nxn}$ es simétrica, entonces existe una base ortonormal de autovectores ${v_1,..,v_n}$ asociados a autovalores $\lambda_1 .. \lambda_n$.

Como la matriz de covarianzas es simétrica, según el teorema, esta tiene una base ortonormal de autovectores por lo que es diagonalizable y es posible expresarse de la forma $Mx = VDV^{t} = U \Sigma V^{t}$ (descomposición SVD de la matriz).

\subsubsection{Método de diagonalización QR}
Utilizando la propiedad de que las matrices simétricas son diagonalizables, se construye el siguiente algoritmo utilizando algún método de factorización QR.

\begin{algorithmic}
  \WHILE{Cota elegida}
    \STATE FactorizaciónQR($A_k$) $\rightarrow Q_k R_k$
    \STATE $A_{k+1} \leftarrow R_k Q_k$
  \ENDWHILE
\end{algorithmic}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Desarrollo                                                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Desarrollo}


\subsection{Método}

Dado un conjunto de $n$ imágenes de entrenamiento $\{x_1, \ldots x_n\}$ con $x_i \in \real^{m \times m}$ y una imagen $x$ que no pertenece al conjunto anterior, queremos identificar el dígito $d$ representado por la imagen $x$.

Sean $X_0, \ldots X_9$ los conjuntos de imágenes de entrenamiento etiquetadas con los dígitos $0, \ldots 9$, respectivamente, y sea $x_j^i \in X_i$ la $j$-ésima imagen etiquetada con el dígito $i$.

Definimos la \textit{transformada característica media} del dígito $i$ como:

$$
tc_i = \frac{\sum_{j=1}^{|X_i|}{tc(x_j^i)}}
            {|X_i|}
$$

Hallamos el dígito $d$, representado por la imagen $x$, de la siguiente manera:

$$
d = \min_{i} || tc_i - tc(x) ||_2
$$

Es decir, identificamos el dígito correspondiente a la imagen $x$ como el dígito cuya transformada característica media se encuentra a menor distancia euclídea de la transformada característica de la imagen $x$.


\subsection{Aproximación de autovectores}

Aplicamos el algoritmo QR para aproximar los autovectores de la matriz de covarianza de las imágenes de entrenamiento $\{x_1, \ldots x_n\}$. 

Como criterio de parada, empleamos una cota superior para la suma del módulo de los elementos por debajo de la diagonal principal de la matriz $A_{k+1}$ obtenida luego de la $k$-ésima iteración del algoritmo.

Implementamos un método de descomposición QR utilizando transformaciones de Householder. La implementación inicial de este método empleaba transformaciones de Givens, pero esta técnica resultó demasiado lenta, por lo que luego fue reemplazado por la implementación actual basada en reflectores.

A continuación, tomamos la matriz diagonal $A$ y la matriz ortogonal $R$ obtenidas de la salida del algoritmo QR. Recordemos que los elementos $a_ii$ de la diagonal de la matriz $A$ aproximan los autovalores de la matriz de covarianza, mientras que la $i$-ésima columna de la matriz $Q$ contiene una aproximación al autovector asociado al autovalor $a_ii$. Para terminar, reordenamos los autovectores por autovalor asociado, de forma decreciente.


\subsection{Experimentos realizados}

En todos los experimentos explicados a continuación se utilizó la base de datos de dígitos manuscritos MNIST\footnote{http://yann.lecun.com/exdb/mnist/}.





% Se realizó la implementación en C++ utilizando la clase Matriz utilizada anteriormente en el TP2 de la materia. A esta se le agregaron entre otros, los métodos de House Holder y Givens para la realización de la diagonalización mediante el método QR de la matriz de covarianza.

% La implementación de Givens resultó ser demasiado lenta (debido a la naturaleza de la matriz Mx) a comparación de la de House Holder a la hora de diagonalizar por lo que la diagonalización de la matriz de covarianza fué realizada mediante House Holder.

% El criterio de parada o cota utilizada para el método de diagonalización fue la suma de los elementos por debajo de la diagonal.

% Una vez obtenida la matriz de autovectores mediante el método de diagonalización, se reordenaron los autovectores y autovalores asociados de forma decreciente en valor absoluto.

% El método elegido para la detección de dígitos fué el siguiente:
% \begin{enumerate}
% \item Del set de entrenamiento, se filtró las imágenes (filas de la matríz de imágenes MISNT) según cáda dígito (0-9) y se armó nuevas matrices con estas.

% \item A cada matríz con las imágenes de los dígitos filtrados se les aplicó $TC(X_{0..9})$ dónde $TC(X) = V^{t} * X^{t}$ realizando una transformación de todas las imágenes en la matriz de cáda dígito.

% $V^{t}$ es reducida según el valor de columnas k elegidas para comprobar la efectividad del método SVD ante la eliminación de la redundancia.

% \item Se creó una nueva matriz a la que llamaremos "matriz de medias" la cuál contiene en sus 10 filas, las medias de las columnas de las matrices filtradas por dígitos y transformadas.

% \item Dado el set de pruebas, se procedió a transformar las imágenes (filas de la matriz obtenida para tests de MNST) utilizando $TC()$ , se les calculó su media y se la comparó con las filas de la matriz de medias con el objetivo de encontrar la fila que produzca el menor error cuadrático entre las diferentes medias y la media obtenida, pudiendo así elegir el dígito correspondiente a la fila que tuviera menor error cuadrático.
% \end{enumerate}

% Este experimento se replicó con diferentes cantidades de imágenes de entrenamiento, con diferentes k's para el cálculo de $TC()$ y con diferentes cotas a la hora del cálculo de autovalores y autovectores.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Resultados                                                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Resultados}


\begin{figure}[H]
  \centering
  \include{tasas-vs-k}
  \caption{Tasa de aciertos en función de $k$}
  \label{tasas-vs-k}
\end{figure}


\begin{figure}[H]
  \centering
  PENDIENTE
  \caption{Tasa de aciertos en función de cota de error del algoritmo QR}
  \label{tasas-vs-cota}
\end{figure}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Discusión                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Discusión}

Observamos un aumento consistente de la tasa de aciertos al incrementar la cantidad de coeficientes principales $k$. Sin embargo, las mejoras en la cantidad de aciertos disminuye considerablemente para valores de $k$ mayores a 40, como se aprecia en la figura \ref{tasas-vs-k}. Esto es de esperar, ya que los coeficientes principales de índices pequeños son los que más información aportan a la imagen.

De manera similar, notamos mejoras en la tasa de aciertos al reducir la cota de error $e$ empleada en el algoritmo QR para la aproximación de autovectores de la matriz de covarianza. La tasa de aciertos se estabiliza alrededor del 80\% para valores $e < *NUMERO*$. Ver figura \ref{tasas-vs-cota}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Conclusiones                                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Conclusiones}

Identificamos la configuración $k = 40$, $e = *NUMERO*$, que arroja una tasa de aciertos de 82\%, como la configuración óptima para aplicaciones que requieren un uso eficiente del tiempo. Ver figuras \ref{tasas-vs-k} y \ref{tasas-vs-cota}.

Se puede obtener una tasa de aciertos superior aumentando la cantidad de coeficientes principales empleada y reduciendo la cota de error del algoritmo QR si así se desea, pero la mejora es muy pequeña comparado con el tiempo extra de ejecución que requiere. Por ejemplo, la configuración $k = 784$ arroja una tasa de aciertos de *NUMERO*\%, pero requiere el 1960\% del tiempo de ejecución que $k = 40$ (784 vs. 40 productos internos, respectivamente.)

La principal ventaja de este método es su facilidad de implementación. Si disponemos previamente de las aproximaciones de los autovectores de la matriz de covarianza y las transformadas características medias de cada dígito, podemos identificar un dígito manuscrito cualquiera computando $k$ productos internos y 10 normas euclídeas. Sin embargo, la tasa de aciertos que arroja este método es muy pequeña para la mayoría de las aplicaciones: una tasa del 80\% identifica incorrectamente 1 de cada 5 dígitos.

Recomendamos el uso de este método para aplicaciones de baja prioridad y en donde el costo de cometer un error es muy pequeño (ejemplo: identificación de CAPTCHAs\footnote{http://en.wikipedia.org/wiki/CAPTCHA}.) Para aplicaciones críticas recomendamos aplicar técnicas alternativas.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Apéndice A: Enunciado del Trabajo Práctico                                %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\newpage

\section{Apéndice A: Enunciado del Trabajo Práctico}

\input{enunciado}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Apéndice B: Código Fuente                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newpage

\section{Apéndice B: Código Fuente}


% \subsection{Metodos.cpp}

% \verbatimtabinput{../Metodos.cpp}

% \subsection{Ecuaciones.cpp}

% \verbatimtabinput{../Ecuaciones.cpp}

% \subsection{Matriz.h}

% \verbatimtabinput{../Matriz.h}

% \subsection{Matriz.cpp}

% \verbatimtabinput{../Matriz.cpp}


\end{document}